{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "4e13b4e6a2339b9177f394100890b4275c358c92e2d14a3cbcee8c2400e7da61"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit ('pyr': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FcXLbzaOH-t",
        "outputId": "3c23580a-d654-4dd6-b547-901978feae8b"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from dateutil import parser\n",
        "import requests\n",
        "import re\n",
        "import dateparser\n",
        "import pickle\n",
        "from nltk.stem import SnowballStemmer\n",
        "import nltk as nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stemmer=SnowballStemmer('portuguese')\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/rhenanqueiroz/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk1Tg8r6OH-0"
      },
      "source": [
        "# Teste g1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMrCihX4OH-2",
        "outputId": "c2b8656d-edd7-495f-86ec-63e5e5db14d1"
      },
      "source": [
        "lista_noticias = []\n",
        "\n",
        "response = requests.get('https://g1.globo.com/resumo-do-dia/noticia/2020/01/27/segunda-feira-27-de-janeiro.ghtml')\n",
        "\n",
        "content = response.content\n",
        "\n",
        "site = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "# HTML da notícia\n",
        "noticias = site.findAll('div', attrs={'class': 'feed-post-body'})\n",
        "\n",
        "for noticia in noticias:\n",
        "  # Título\n",
        "  titulo = noticia.find('a', attrs={'class': 'feed-post-link'})\n",
        "\n",
        "  # print(titulo.text)\n",
        "  # print(titulo['href']) # link da notícia\n",
        "\n",
        "  site_noticia = BeautifulSoup(requests.get(titulo['href']).content, 'html.parser')\n",
        "  textos_noticia = site_noticia.findAll('p', class_=\"content-text__container\")\n",
        "  texto_noticia = \" \".join([noti.getText() for noti in textos_noticia])\n",
        "\n",
        "  # Subtítulo: div class=\"feed-post-body-resumo\"\n",
        "  subtitulo = noticia.find('div', attrs={'class': 'feed-post-body-resumo'})\n",
        "\n",
        "  if (subtitulo):\n",
        "    # print(subtitulo.text)\n",
        "    lista_noticias.append([titulo.text, subtitulo.text, titulo['href'], texto_noticia])\n",
        "  else:\n",
        "    lista_noticias.append([titulo.text, '', titulo['href'], texto_noticia])\n",
        "\n",
        "\n",
        "news = pd.DataFrame(lista_noticias, columns=['Título', 'Subtítulo', 'Link', 'Noticia'])\n",
        "news\n",
        "#news.to_excel('noticias.xlsx', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Título</th>\n",
              "      <th>Subtítulo</th>\n",
              "      <th>Link</th>\n",
              "      <th>Noticia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>STF nega pedido para obrigar Alcolumbre a marc...</td>\n",
              "      <td>Bolsonaro indicou ex-ministro para cadeira no ...</td>\n",
              "      <td>https://g1.globo.com/politica/noticia/2021/10/...</td>\n",
              "      <td>O ministro do Supremo Tribunal Federal (STF) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Moraes prorroga inquéritos sobre 'milícia digi...</td>\n",
              "      <td>Depoimento do presidente em uma das investigaç...</td>\n",
              "      <td>https://g1.globo.com/politica/noticia/2021/10/...</td>\n",
              "      <td>O ministro do Supremo Tribunal Federal (STF) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Justiça impede Sérgio Camargo de nomear ou exo...</td>\n",
              "      <td>Presidente da entidade foi denunciado por pers...</td>\n",
              "      <td>https://g1.globo.com/df/distrito-federal/notic...</td>\n",
              "      <td>A 21ª Vara do Trabalho de Brasília decidiu, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7 presos, o alvo, disputa do tráfico: o que se...</td>\n",
              "      <td>Brasileiros foram detidos pela polícia paragua...</td>\n",
              "      <td>https://g1.globo.com/ms/mato-grosso-do-sul/not...</td>\n",
              "      <td>Na madrugada de sábado (10), quatro pessoas f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VÍDEO: vítimas foram executadas logo após entr...</td>\n",
              "      <td></td>\n",
              "      <td>https://g1.globo.com/ms/mato-grosso-do-sul/not...</td>\n",
              "      <td>Imagens de câmeras de segurança de uma loja m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ações da Embraer sobem 5% após venda de 100 ae...</td>\n",
              "      <td>NetJets, de Warren Buffett, fez encomenda que ...</td>\n",
              "      <td>https://g1.globo.com/economia/noticia/2021/10/...</td>\n",
              "      <td>As ações da Embraer tiveram alta de 5% nesta ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Dólar sobe mais e fecha no maior valor em quas...</td>\n",
              "      <td></td>\n",
              "      <td>https://g1.globo.com/economia/noticia/2021/10/...</td>\n",
              "      <td>O dólar fechou em alta nesta segunda-feira (1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Queda de avião de pequeno porte provoca incênd...</td>\n",
              "      <td></td>\n",
              "      <td>https://g1.globo.com/mundo/noticia/2021/10/11/...</td>\n",
              "      <td>Um pequeno avião caiu em um bairro no subúrbi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Itamaraty revoga nomeação de eliminado por cot...</td>\n",
              "      <td>Lucas Siqueira foi eliminado por fraude, mas e...</td>\n",
              "      <td>https://g1.globo.com/df/distrito-federal/notic...</td>\n",
              "      <td>O Ministério das Relações Exteriores (MRE) re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Imagens aéreas mostram destruição causada por ...</td>\n",
              "      <td>Fenômeno provocou tempestade com granizo e for...</td>\n",
              "      <td>https://g1.globo.com/sp/sao-carlos-regiao/noti...</td>\n",
              "      <td>Imagens aéreas feitas por drones mostraram o ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Título  \\\n",
              "0  STF nega pedido para obrigar Alcolumbre a marc...   \n",
              "1  Moraes prorroga inquéritos sobre 'milícia digi...   \n",
              "2  Justiça impede Sérgio Camargo de nomear ou exo...   \n",
              "3  7 presos, o alvo, disputa do tráfico: o que se...   \n",
              "4  VÍDEO: vítimas foram executadas logo após entr...   \n",
              "5  Ações da Embraer sobem 5% após venda de 100 ae...   \n",
              "6  Dólar sobe mais e fecha no maior valor em quas...   \n",
              "7  Queda de avião de pequeno porte provoca incênd...   \n",
              "8  Itamaraty revoga nomeação de eliminado por cot...   \n",
              "9  Imagens aéreas mostram destruição causada por ...   \n",
              "\n",
              "                                           Subtítulo  \\\n",
              "0  Bolsonaro indicou ex-ministro para cadeira no ...   \n",
              "1  Depoimento do presidente em uma das investigaç...   \n",
              "2  Presidente da entidade foi denunciado por pers...   \n",
              "3  Brasileiros foram detidos pela polícia paragua...   \n",
              "4                                                      \n",
              "5  NetJets, de Warren Buffett, fez encomenda que ...   \n",
              "6                                                      \n",
              "7                                                      \n",
              "8  Lucas Siqueira foi eliminado por fraude, mas e...   \n",
              "9  Fenômeno provocou tempestade com granizo e for...   \n",
              "\n",
              "                                                Link  \\\n",
              "0  https://g1.globo.com/politica/noticia/2021/10/...   \n",
              "1  https://g1.globo.com/politica/noticia/2021/10/...   \n",
              "2  https://g1.globo.com/df/distrito-federal/notic...   \n",
              "3  https://g1.globo.com/ms/mato-grosso-do-sul/not...   \n",
              "4  https://g1.globo.com/ms/mato-grosso-do-sul/not...   \n",
              "5  https://g1.globo.com/economia/noticia/2021/10/...   \n",
              "6  https://g1.globo.com/economia/noticia/2021/10/...   \n",
              "7  https://g1.globo.com/mundo/noticia/2021/10/11/...   \n",
              "8  https://g1.globo.com/df/distrito-federal/notic...   \n",
              "9  https://g1.globo.com/sp/sao-carlos-regiao/noti...   \n",
              "\n",
              "                                             Noticia  \n",
              "0   O ministro do Supremo Tribunal Federal (STF) ...  \n",
              "1   O ministro do Supremo Tribunal Federal (STF) ...  \n",
              "2   A 21ª Vara do Trabalho de Brasília decidiu, n...  \n",
              "3   Na madrugada de sábado (10), quatro pessoas f...  \n",
              "4   Imagens de câmeras de segurança de uma loja m...  \n",
              "5   As ações da Embraer tiveram alta de 5% nesta ...  \n",
              "6   O dólar fechou em alta nesta segunda-feira (1...  \n",
              "7   Um pequeno avião caiu em um bairro no subúrbi...  \n",
              "8   O Ministério das Relações Exteriores (MRE) re...  \n",
              "9   Imagens aéreas feitas por drones mostraram o ...  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_LbVUHNOH-4"
      },
      "source": [
        "import datetime\n",
        "weekday_name = [\"segunda-feira\", \"terca-feira\", \"quarta-feira\", \"quinta-feira\", \"sexta-feira\", \"sabado\", \"domingo\"]\n",
        "months = [\"Unknown\", \"janeiro\", \"fevereiro\", \"marco\", \"abril\", \"maio\", \"junho\", \"julho\", \"agosto\", \"setembro\", \"outubro\",\"novembro\", \"dezembro\"]\n",
        "\n",
        "def return_url(dt):\n",
        "    prefix = 'https://g1.globo.com/resumo-do-dia/noticia/'\n",
        "    data_yyyy_mm_dd = str(dt.year) + '/' + dt.strftime('%m') + '/' + dt.strftime('%d') + '/'\n",
        "\n",
        "    data_extenso = weekday_name[dt.weekday()] + '-' + str(dt.day) + '-de-' + months[dt.month] #para datas em que mostram 7-janeiro\n",
        "    #data_extenso = weekday_name[dt.weekday()] + '-' + str(dt.strftime('%d')) + '-de-' + months[dt.month] #para datas em que mostram 07-janeiro\n",
        "    sufix = '.ghtml'\n",
        "\n",
        "    link_url = prefix + data_yyyy_mm_dd + data_extenso + sufix\n",
        "    return link_url\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pGTgSpEOH-6"
      },
      "source": [
        "from dateutil import parser\n",
        "import requests\n",
        "\n",
        "headers = {\n",
        "    'Accept-Encoding': 'gzip, deflate, sdch',\n",
        "    'Accept-Language': 'en-US,en;q=0.8',\n",
        "    'Upgrade-Insecure-Requests': '1',\n",
        "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "    'Cache-Control': 'max-age=0',\n",
        "    'Connection': 'keep-alive',\n",
        "}\n",
        "\n",
        "def df_noticias(url):\n",
        "    '''\n",
        "    Função para capturar o título, texto e data de publicação de cada noticia no site resumo do g1\n",
        "    '''\n",
        "\n",
        "    # transforma o objeto url na forma do bs4\n",
        "    site = BeautifulSoup(requests.get(url, headers = headers).content, 'html.parser')\n",
        "\n",
        "    #encontra todos os links de noticias do site de resumo diário\n",
        "    links_noticias = site.findAll('p', attrs={'class': 'content-text__container'})\n",
        "    lista_links = [link.find('a').get('href') for link in links_noticias if link.find('a') != None]\n",
        "\n",
        "    #Cria lista vazia das noticias do dia com os links\n",
        "    lista_noticias = []\n",
        "    try:\n",
        "        for link in lista_links:\n",
        "\n",
        "            #Entra no link de cada noticia\n",
        "            site_noticia = BeautifulSoup(requests.get(link, headers = headers).content, 'html.parser')\n",
        "\n",
        "            #Pega o título\n",
        "            titulo = site_noticia.find('h1', attrs={'class': 'content-head__title'})\n",
        "\n",
        "            #Pega a data de publicação\n",
        "            data = site_noticia.find('time', attrs={'itemprop': 'datePublished'})\n",
        "            try:\n",
        "                date_time_str = data.get('datetime')\n",
        "                date_time = parser.parse(date_time_str).date()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            #Pega o conteúdo textual\n",
        "            textos_noticia = site_noticia.findAll('p', class_=\"content-text__container\")\n",
        "            texto_noticia = \" \".join([noti.getText() for noti in textos_noticia])\n",
        "\n",
        "            if (titulo and data and texto_noticia):\n",
        "                lista_noticias.append([link, titulo.text, date_time, texto_noticia])\n",
        "            else:\n",
        "                pass\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    #retorna o dataframe com as infos\n",
        "    return pd.DataFrame(lista_noticias, columns=['link','titulo', 'data_pub','noticias'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BteuP2VzOH-8"
      },
      "source": [
        "def salva_bases(data_in, data_out, ref):\n",
        "    df = pd.DataFrame()\n",
        "    lista_datas = pd.bdate_range(start=data_in, end=data_out)\n",
        "    for data in lista_datas:\n",
        "        url = return_url(data)\n",
        "        df = df.append(df_noticias(url))\n",
        "    df = df.reset_index().drop(columns = ['index'])\n",
        "\n",
        "    caminho = \"/Users/rhenanqueiroz/Documents/GitHub/fakenews/materias_g1/g1_\" + ref + \".pkl\"\n",
        "    df.to_pickle(caminho)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfMI4UpdOH-9"
      },
      "source": [
        "#salva_bases('08/01/2018', '08/31/2018', \"201808\")\n",
        "#salva_bases('09/01/2018', '09/29/2018', \"201809\")\n",
        "#salva_bases('10/01/2018', '10/29/2018', \"201810\")\n",
        "#salva_bases('11/01/2018', '11/30/2018', \"201811\")\n",
        "#salva_bases('12/01/2018', '12/31/2018', \"201812\")\n",
        "#salva_bases('10/01/2018', '10/31/2018', \"201810\")\n",
        "#salva_bases('01/01/2019', '01/31/2019', \"201901\")\n",
        "#salva_bases('02/01/2019', '02/28/2019', \"201902\")\n",
        "#salva_bases('03/01/2019', '03/31/2019', \"201903\")\n",
        "#salva_bases('04/01/2019', '04/30/2019', \"201904\")\n",
        "#salva_bases('05/01/2019', '05/31/2019', \"201905\")\n",
        "#salva_bases('06/01/2019', '06/30/2019', \"201906\")\n",
        "#salva_bases('07/01/2019', '07/31/2019', \"201907\")\n",
        "#salva_bases('08/01/2019', '08/31/2019', \"201908\")\n",
        "#salva_bases('09/01/2019', '09/30/2019', \"201909\")\n",
        "#salva_bases('10/01/2019', '10/31/2019', \"201910\")\n",
        "#salva_bases('11/01/2019', '11/30/2019', \"201911\")\n",
        "#salva_bases('12/01/2019', '12/31/2019', \"201912\")\n",
        "#salva_bases('01/01/2020', '01/31/2020', \"202001\")\n",
        "#salva_bases('02/01/2020', '02/29/2020', \"202002\")\n",
        "#salva_bases('03/01/2020', '03/31/2020', \"202003\")\n",
        "#salva_bases('04/01/2020', '04/30/2020', \"202004\")\n",
        "#salva_bases('05/01/2020', '05/31/2020', \"202005\")\n",
        "#salva_bases('06/01/2020', '06/30/2020', \"202006\")\n",
        "#salva_bases('07/01/2020', '07/30/2020', \"202007\")\n",
        "#salva_bases('08/01/2020', '08/31/2020', \"202008\")\n",
        "#salva_bases('09/01/2020', '09/30/2020', \"202009\")\n",
        "#salva_bases('10/01/2020', '10/31/2020', \"202010\")\n",
        "#salva_bases('11/01/2020', '11/30/2020', \"202011\")\n",
        "#salva_bases('12/01/2020', '12/31/2020', \"202012\")\n",
        "#salva_bases('01/01/2021', '01/31/2020', \"202101\")\n",
        "#salva_bases('02/01/2021', '02/28/2021', \"202102\")\n",
        "#salva_bases('03/01/2021', '03/31/2021', \"202103\")\n",
        "#salva_bases('04/01/2021', '04/30/2021', \"202104\")\n",
        "#salva_bases('05/01/2021', '05/31/2021', \"202105\")\n",
        "#salva_bases('06/01/2021', '06/30/2021', \"202106\")\n",
        "#salva_bases('07/01/2021', '07/30/2021', \"202107\")\n",
        "#salva_bases('08/01/2021', '08/31/2021', \"202108\")\n",
        "#salva_bases('09/01/2021', '09/30/2021', \"202109\")\n",
        "#salva_bases('10/01/2021', '10/25/2021', \"202110\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwnS2jYwOH--",
        "outputId": "d3201290-3995-4a54-951e-4d0bccf7a3c1"
      },
      "source": [
        "import pickle\n",
        "df_g1 = pd.DataFrame(columns=['link', 'titulo', 'data_pub', 'noticias']) # Creates an empty list\n",
        "\n",
        "for root, dirs, files in os.walk(\"/Users/rhenanqueiroz/Documents/GitHub/fakenews/materias_g1/textos/\"):\n",
        "    for file in files:\n",
        "        print(file)\n",
        "        opencontacts = open(os.getcwd() + \"/materias_g1/\" + file, 'rb')\n",
        "        loadedcontacts = pickle.load(opencontacts)\n",
        "        df_g1 = df_g1.append(loadedcontacts)\n",
        "\n",
        "df_g1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "g1_201909.pkl\n",
            "g1_201908.pkl\n",
            "g1_202008.pkl\n",
            "g1_202009.pkl\n",
            "g1_201809.pkl\n",
            "g1_201808.pkl\n",
            "g1_202108.pkl\n",
            "g1_202109.pkl\n",
            "g1_202107.pkl\n",
            "g1_202106.pkl\n",
            "g1_202104.pkl\n",
            "g1_202110.pkl\n",
            "g1_202105.pkl\n",
            "g1_202101.pkl\n",
            "g1_201811.pkl\n",
            "g1_201810.pkl\n",
            "g1_202102.pkl\n",
            "g1_201812.pkl\n",
            "g1_202103.pkl\n",
            "g1_202004.pkl\n",
            "g1_202010.pkl\n",
            "g1_202011.pkl\n",
            "g1_202005.pkl\n",
            "g1_201901.pkl\n",
            "g1_201903.pkl\n",
            "g1_202007.pkl\n",
            "g1_202006.pkl\n",
            "g1_202012.pkl\n",
            "g1_201902.pkl\n",
            "g1_201906.pkl\n",
            "g1_201912.pkl\n",
            "g1_202002.pkl\n",
            "g1_202003.pkl\n",
            "g1_201907.pkl\n",
            "g1_201911.pkl\n",
            "g1_201905.pkl\n",
            "g1_202001.pkl\n",
            "g1_201904.pkl\n",
            "g1_201910.pkl\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>titulo</th>\n",
              "      <th>data_pub</th>\n",
              "      <th>noticias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://g1.globo.com/politica/noticia/2019/09/...</td>\n",
              "      <td>'Um dos dois ou os dois perderão a cabeça', di...</td>\n",
              "      <td>2019-09-02</td>\n",
              "      <td>O presidente Jair Bolsonaro informou nesta se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://g1.globo.com/politica/noticia/2019/09/...</td>\n",
              "      <td>Bolsonaro diz que vai à ONU 'nem que seja de c...</td>\n",
              "      <td>2019-09-02</td>\n",
              "      <td>O presidente Jair Bolsonaro afirmou nesta seg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://g1.globo.com/natureza/noticia/2019/09/...</td>\n",
              "      <td>Focos de queimadas na Amazônia são quase 20 mi...</td>\n",
              "      <td>2019-09-02</td>\n",
              "      <td>Até o dia 29 de setembro foram registrados 19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://g1.globo.com/natureza/noticia/2019/09/...</td>\n",
              "      <td>Agosto tem o maior número de focos de queimada...</td>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>As queimadas no bioma Amazônia aumentaram 196...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://g1.globo.com/politica/noticia/2019/09/...</td>\n",
              "      <td>38% reprovam e 29% aprovam o governo Bolsonaro...</td>\n",
              "      <td>2019-09-02</td>\n",
              "      <td>Pesquisa Datafolha divulgada nesta segunda-fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>https://g1.globo.com/mundo/noticia/2019/10/31/...</td>\n",
              "      <td>Câmara dos EUA aprova regras para seguir inqué...</td>\n",
              "      <td>2019-10-31</td>\n",
              "      <td>Os democratas na Câmara dos Deputados dos Est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>https://g1.globo.com/loterias/noticia/2019/10/...</td>\n",
              "      <td>Governo autoriza a Caixa a reajustar preço das...</td>\n",
              "      <td>2019-10-31</td>\n",
              "      <td>O Ministério da Economia autorizou a Caixa Ec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>https://globoesporte.globo.com/ginastica-artis...</td>\n",
              "      <td>Acusado de abuso sexual, ex-técnico da ginásti...</td>\n",
              "      <td>2019-10-31</td>\n",
              "      <td>O ex-técnico da seleção masculina de ginástic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>https://g1.globo.com/pop-arte/noticia/2019/10/...</td>\n",
              "      <td>Halloween: veja fantasias dos famosos em festa...</td>\n",
              "      <td>2019-10-31</td>\n",
              "      <td>O Halloween é comemorado nesta quinta-feira (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>https://g1.globo.com/mg/minas-gerais/noticia/2...</td>\n",
              "      <td>Desenhos descobertos em porão que já foi senza...</td>\n",
              "      <td>2019-10-31</td>\n",
              "      <td>Em uma das paredes do porão de um dos casarõe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11907 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  link  \\\n",
              "0    https://g1.globo.com/politica/noticia/2019/09/...   \n",
              "1    https://g1.globo.com/politica/noticia/2019/09/...   \n",
              "2    https://g1.globo.com/natureza/noticia/2019/09/...   \n",
              "3    https://g1.globo.com/natureza/noticia/2019/09/...   \n",
              "4    https://g1.globo.com/politica/noticia/2019/09/...   \n",
              "..                                                 ...   \n",
              "353  https://g1.globo.com/mundo/noticia/2019/10/31/...   \n",
              "354  https://g1.globo.com/loterias/noticia/2019/10/...   \n",
              "355  https://globoesporte.globo.com/ginastica-artis...   \n",
              "356  https://g1.globo.com/pop-arte/noticia/2019/10/...   \n",
              "357  https://g1.globo.com/mg/minas-gerais/noticia/2...   \n",
              "\n",
              "                                                titulo    data_pub  \\\n",
              "0    'Um dos dois ou os dois perderão a cabeça', di...  2019-09-02   \n",
              "1    Bolsonaro diz que vai à ONU 'nem que seja de c...  2019-09-02   \n",
              "2    Focos de queimadas na Amazônia são quase 20 mi...  2019-09-02   \n",
              "3    Agosto tem o maior número de focos de queimada...  2019-09-01   \n",
              "4    38% reprovam e 29% aprovam o governo Bolsonaro...  2019-09-02   \n",
              "..                                                 ...         ...   \n",
              "353  Câmara dos EUA aprova regras para seguir inqué...  2019-10-31   \n",
              "354  Governo autoriza a Caixa a reajustar preço das...  2019-10-31   \n",
              "355  Acusado de abuso sexual, ex-técnico da ginásti...  2019-10-31   \n",
              "356  Halloween: veja fantasias dos famosos em festa...  2019-10-31   \n",
              "357  Desenhos descobertos em porão que já foi senza...  2019-10-31   \n",
              "\n",
              "                                              noticias  \n",
              "0     O presidente Jair Bolsonaro informou nesta se...  \n",
              "1     O presidente Jair Bolsonaro afirmou nesta seg...  \n",
              "2     Até o dia 29 de setembro foram registrados 19...  \n",
              "3     As queimadas no bioma Amazônia aumentaram 196...  \n",
              "4     Pesquisa Datafolha divulgada nesta segunda-fe...  \n",
              "..                                                 ...  \n",
              "353   Os democratas na Câmara dos Deputados dos Est...  \n",
              "354   O Ministério da Economia autorizou a Caixa Ec...  \n",
              "355   O ex-técnico da seleção masculina de ginástic...  \n",
              "356   O Halloween é comemorado nesta quinta-feira (...  \n",
              "357   Em uma das paredes do porão de um dos casarõe...  \n",
              "\n",
              "[11907 rows x 4 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExoV7IR9OH-_"
      },
      "source": [
        "df = df_g1.reset_index().drop(columns = ['index'])\n",
        "\n",
        "caminho = \"/Users/rhenanqueiroz/Documents/GitHub/fakenews/g1_geral.pkl\"\n",
        "df.to_pickle(caminho)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeh7MYE1OH_A"
      },
      "source": [
        "# Terça livre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zNuX1o2OH_B"
      },
      "source": [
        "url = 'https://tercalivre.com.br/mais-noticias/page/800/'\n",
        "# transforma o objeto url na forma do bs4\n",
        "site = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
        "\n",
        "#encontra todos os links de noticias do site de resumo diário\n",
        "links_noticias = site.findAll('h2', attrs={'class': 'entry-title h7'})\n",
        "lista_links = [link.find('a').get('href') for link in links_noticias if link.find('a') != None]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R09g9KG1OH_B",
        "outputId": "927ee8b6-421f-4949-b847-99d2c40081bb"
      },
      "source": [
        "lista_links[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://tercalivre.com.br/filho-de-renan-calheiros-enfrentara-o-psdb-em-alagoas-o-senador-vai-disputar-com-os-ministros-de-temer/'"
            ]
          },
          "execution_count": 402,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmwGTNLgOH_C"
      },
      "source": [
        "def df_noticias_terca_livre(url):\n",
        "    '''\n",
        "    Função para capturar o título, texto e data de publicação de cada noticia no site resumo do terça livre\n",
        "    '''\n",
        "    import re\n",
        "    import dateparser\n",
        "    # transforma o objeto url na forma do bs4\n",
        "    site = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
        "\n",
        "    #encontra todos os links de noticias do site de resumo diário\n",
        "    links_noticias = site.findAll('h2', attrs={'class': 'entry-title h7'})\n",
        "    lista_links = [link.find('a').get('href') for link in links_noticias if link.find('a') != None]\n",
        "\n",
        "    #Cria lista vazia das noticias do dia com os links\n",
        "    lista_noticias = []\n",
        "\n",
        "    for link in lista_links:\n",
        "\n",
        "        #Entra no link de cada noticia\n",
        "        site_noticia = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
        "\n",
        "        #Pega o título\n",
        "        titulo = site_noticia.find('h1', attrs={'class': 'entry-title h1'})\n",
        "\n",
        "        #Pega a data de publicação\n",
        "\n",
        "        data = site_noticia.find('span', attrs={'class': 'updated'})\n",
        "        try:\n",
        "            date_time_str = dateparser.parse(data.get_text(), languages=[\"pt\"]).strftime('%Y-%m-%d')\n",
        "            date_time = parser.parse(date_time_str).date()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        #Pega o conteúdo textual\n",
        "        textos_noticia = site_noticia.findAll('p')\n",
        "        texto_noticia = \" \".join([noti.getText() for noti in textos_noticia])\n",
        "        texto_noticia2 = re.sub(r\"Comentário Nome [\\s\\S]*/+\", ' ', texto_noticia)\n",
        "\n",
        "        if (titulo and data and texto_noticia2 and \"#\" not in titulo.text and len(texto_noticia2)>100):\n",
        "            lista_noticias.append([link, titulo.text, date_time, texto_noticia2])\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    #retorna o dataframe com as infos\n",
        "    return pd.DataFrame(lista_noticias, columns=['link','titulo', 'data_pub','noticias'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-xG2qV8OH_D",
        "outputId": "eb4fceab-2b2b-4b8a-c52e-57ada8804d95"
      },
      "source": [
        "df = df_noticias_terca_livre('https://tercalivre.com.br/mais-noticias/page/800/')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>titulo</th>\n",
              "      <th>data_pub</th>\n",
              "      <th>noticias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://tercalivre.com.br/intervencao-federal-...</td>\n",
              "      <td>Intervenção Federal: uma guerra onde só um lad...</td>\n",
              "      <td>2018-02-21</td>\n",
              "      <td>Ainda ontem, 20, um sargento do exército morre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://tercalivre.com.br/diante-do-que-o-rj-e...</td>\n",
              "      <td>Diante do que o RJ enfrenta, a preocupação da ...</td>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>A Rede Globo de televisão flagrou um homem da ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://tercalivre.com.br/analista-politico-qu...</td>\n",
              "      <td>Analista político que acertou resultados de Tr...</td>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>Em entrevista ao InfoMoney, o analista polític...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://tercalivre.com.br/prazo-para-defesa-de...</td>\n",
              "      <td>Prazo para defesa de Lula encerra hoje. TRF-4 ...</td>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>O prazo para que a defesa do ex-presidente con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://tercalivre.com.br/grave-paraclitus-afi...</td>\n",
              "      <td>GRAVE: Paraclitus afirma que Campanha da Frate...</td>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>Uma denúncia gravíssima foi publicada pelo sit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>https://tercalivre.com.br/depois-da-intervenca...</td>\n",
              "      <td>Depois da intervenção, ministro já fala em can...</td>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>Em entrevista à Rádio Gaúcha, o ministro da Ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>https://tercalivre.com.br/filho-de-renan-calhe...</td>\n",
              "      <td>Filho de Renan Calheiros enfrentará o PSDB em ...</td>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>Em Alagoas, tanto o senador Renan Calheiros (M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>https://tercalivre.com.br/maduro-desafia-trump...</td>\n",
              "      <td>Maduro desafia Trump em nome da revolução boli...</td>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>O ditador da Venezuela Nicolás Maduro (que alg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>https://tercalivre.com.br/juiz-reage-assalto-p...</td>\n",
              "      <td>Juiz reage a assalto, persegue criminosos e fe...</td>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>Uma tentativa de assalto à casa de um juiz na ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>https://tercalivre.com.br/homens-que-tatuaram-...</td>\n",
              "      <td>Homens que tatuaram testa de adolescente são c...</td>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>Os dois homens que tatuaram a testa de um adol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>https://tercalivre.com.br/funcionario-da-onu-q...</td>\n",
              "      <td>Funcionário da ONU quer que a América Latina m...</td>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>O alto comissário das Nações Unidas para os Re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 link  \\\n",
              "0   https://tercalivre.com.br/intervencao-federal-...   \n",
              "1   https://tercalivre.com.br/diante-do-que-o-rj-e...   \n",
              "2   https://tercalivre.com.br/analista-politico-qu...   \n",
              "3   https://tercalivre.com.br/prazo-para-defesa-de...   \n",
              "4   https://tercalivre.com.br/grave-paraclitus-afi...   \n",
              "5   https://tercalivre.com.br/depois-da-intervenca...   \n",
              "6   https://tercalivre.com.br/filho-de-renan-calhe...   \n",
              "7   https://tercalivre.com.br/maduro-desafia-trump...   \n",
              "8   https://tercalivre.com.br/juiz-reage-assalto-p...   \n",
              "9   https://tercalivre.com.br/homens-que-tatuaram-...   \n",
              "10  https://tercalivre.com.br/funcionario-da-onu-q...   \n",
              "\n",
              "                                               titulo    data_pub  \\\n",
              "0   Intervenção Federal: uma guerra onde só um lad...  2018-02-21   \n",
              "1   Diante do que o RJ enfrenta, a preocupação da ...  2018-02-20   \n",
              "2   Analista político que acertou resultados de Tr...  2018-02-20   \n",
              "3   Prazo para defesa de Lula encerra hoje. TRF-4 ...  2018-02-20   \n",
              "4   GRAVE: Paraclitus afirma que Campanha da Frate...  2018-02-20   \n",
              "5   Depois da intervenção, ministro já fala em can...  2018-02-20   \n",
              "6   Filho de Renan Calheiros enfrentará o PSDB em ...  2018-02-20   \n",
              "7   Maduro desafia Trump em nome da revolução boli...  2018-02-20   \n",
              "8   Juiz reage a assalto, persegue criminosos e fe...  2018-02-19   \n",
              "9   Homens que tatuaram testa de adolescente são c...  2018-02-19   \n",
              "10  Funcionário da ONU quer que a América Latina m...  2018-02-19   \n",
              "\n",
              "                                             noticias  \n",
              "0   Ainda ontem, 20, um sargento do exército morre...  \n",
              "1   A Rede Globo de televisão flagrou um homem da ...  \n",
              "2   Em entrevista ao InfoMoney, o analista polític...  \n",
              "3   O prazo para que a defesa do ex-presidente con...  \n",
              "4   Uma denúncia gravíssima foi publicada pelo sit...  \n",
              "5   Em entrevista à Rádio Gaúcha, o ministro da Ca...  \n",
              "6   Em Alagoas, tanto o senador Renan Calheiros (M...  \n",
              "7   O ditador da Venezuela Nicolás Maduro (que alg...  \n",
              "8   Uma tentativa de assalto à casa de um juiz na ...  \n",
              "9   Os dois homens que tatuaram a testa de um adol...  \n",
              "10  O alto comissário das Nações Unidas para os Re...  "
            ]
          },
          "execution_count": 472,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m-o_iYdOH_D"
      },
      "source": [
        "def salva_bases_tl(cent1,cent2):\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    for numero in range(cent1,cent2):\n",
        "        url = 'https://tercalivre.com.br/mais-noticias/page/' + str(numero) + '/'\n",
        "        df = df.append(df_noticias_terca_livre(url))\n",
        "    df = df.reset_index().drop(columns = ['index'])\n",
        "\n",
        "    caminho = \"/Users/rhenanqueiroz/Documents/GitHub/fakenews/tl_\" + str(cent2) + \".pkl\"\n",
        "    df.to_pickle(caminho)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9cT29DzOH_D"
      },
      "source": [
        "salva_bases_tl(100,101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIFb6n3OOH_E",
        "outputId": "ed477e20-2f5c-415c-ee7d-361c696e593b"
      },
      "source": [
        "df_2017 = pd.read_csv('/Users/rhenanqueiroz/Downloads/articles_pre_processed.csv', sep = '|')\n",
        "df_2017"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>com a possibilidade de uma condenacao impedir ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>para oumou sangare cantora e ativista malinesa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>tres reportagens da folha foram vencedoras do ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a disney divulgou na noite desta segundafeira ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>o cbss banco da holding elopar dos socios brad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165661</th>\n",
              "      <td>165661</td>\n",
              "      <td>o tucano beto richa tinha tudo para comecar se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165662</th>\n",
              "      <td>165662</td>\n",
              "      <td>o economista renan filho pmdb assume nesta qui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165663</th>\n",
              "      <td>165663</td>\n",
              "      <td>destaques da programacao desta quintafeira 1º ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165664</th>\n",
              "      <td>165664</td>\n",
              "      <td>o lider nortecoreano kim jongun disse nesta qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165665</th>\n",
              "      <td>165665</td>\n",
              "      <td>o projeto de que heitor maia neto mais se orgu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>165666 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0                                               Text\n",
              "0                0  com a possibilidade de uma condenacao impedir ...\n",
              "1                1  para oumou sangare cantora e ativista malinesa...\n",
              "2                2  tres reportagens da folha foram vencedoras do ...\n",
              "3                3  a disney divulgou na noite desta segundafeira ...\n",
              "4                4  o cbss banco da holding elopar dos socios brad...\n",
              "...            ...                                                ...\n",
              "165661      165661  o tucano beto richa tinha tudo para comecar se...\n",
              "165662      165662  o economista renan filho pmdb assume nesta qui...\n",
              "165663      165663  destaques da programacao desta quintafeira 1º ...\n",
              "165664      165664  o lider nortecoreano kim jongun disse nesta qu...\n",
              "165665      165665  o projeto de que heitor maia neto mais se orgu...\n",
              "\n",
              "[165666 rows x 2 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_VZfFx6OH_E"
      },
      "source": [
        "# Senso Incomum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgNwLYluOH_F"
      },
      "source": [
        "import datetime\n",
        "def return_url_senso_incomum(dt):\n",
        "    prefix = 'https://sensoincomum.org/'\n",
        "    data_yyyy_mm_dd = str(dt.year) + '/' + dt.strftime('%m') + '/' + dt.strftime('%d') + '/'\n",
        "\n",
        "    link_url = prefix + data_yyyy_mm_dd\n",
        "    return link_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkyaECTcOH_F"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "def df_noticias_senso_incomum(url):\n",
        "    '''\n",
        "    Função para capturar o título, texto e data de publicação de cada noticia no site resumo do terça livre\n",
        "    '''\n",
        "    import re\n",
        "    import dateparser\n",
        "    # transforma o objeto url na forma do bs4\n",
        "    site = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
        "\n",
        "    #encontra todos os links de noticias do site de resumo diário\n",
        "    links_noticias = site.findAll('a', attrs={'class': 'tt-post-title titulo-cat'})\n",
        "    lista_links = [link.get('href') for link in links_noticias]\n",
        "    if lista_links:\n",
        "        #Cria lista vazia das noticias do dia com os links\n",
        "        lista_noticias = []\n",
        "\n",
        "        for link in lista_links:\n",
        "\n",
        "            #Entra no link de cada noticia\n",
        "            site_noticia = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "            #Pega o título\n",
        "            titulo = site_noticia.find('h1', attrs={'class': 'c-h1 text-center'})\n",
        "\n",
        "\n",
        "            #Pega a data de publicação\n",
        "            data = site_noticia.find('span', attrs={'class': 'tt-post-date-single'})\n",
        "            try:\n",
        "                date_time_str = dateparser.parse(data.get_text(), languages=[\"pt\"]).strftime('%Y-%m-%d')\n",
        "                date_time = parser.parse(date_time_str).date()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            #Pega o conteúdo textual\n",
        "            container = site_noticia.find('article')\n",
        "            textos_noticia = container.findAll('p')\n",
        "            texto_noticia = \" \".join([noti.getText() for noti in textos_noticia])\n",
        "\n",
        "            if (titulo and data and texto_noticia and len(texto_noticia)>100):\n",
        "                lista_noticias.append([link, titulo.text, date_time, texto_noticia])\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "\n",
        "        #retorna o dataframe com as infos\n",
        "        return pd.DataFrame(lista_noticias, columns=['link','titulo', 'data_pub','noticias'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTniubG5OH_G"
      },
      "source": [
        "def salva_bases_senso_incomum(data_in, data_out, ref):\n",
        "    df = pd.DataFrame()\n",
        "    lista_datas = pd.bdate_range(start=data_in, end=data_out)\n",
        "    for data in lista_datas:\n",
        "        url = return_url(data)\n",
        "        df = df.append(df_noticias(url))\n",
        "    df = df.reset_index().drop(columns = ['index'])\n",
        "\n",
        "    caminho = \"/Users/rhenanqueiroz/Documents/GitHub/fakenews/senso_incomum_\" + ref + \".pkl\"\n",
        "    df.to_pickle(caminho)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FhJ9-EeOH_G"
      },
      "source": [
        "#salva_bases_senso_incomum('01-01-2017', '10-28-2021',\"geral\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8oVCeL_OH_H"
      },
      "source": [
        "# Jornal da cidade online"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_x4uBibOH_H"
      },
      "source": [
        "def return_url_jornal_cidade_online(ref):\n",
        "    prefix = 'https://www.jornaldacidadeonline.com.br/noticias/'\n",
        "    sufix = str(ref) + '/'\n",
        "    link_url = prefix + sufix\n",
        "    return link_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqLz4PlzOH_I"
      },
      "source": [
        "def df_jornal_cidade_online(url):\n",
        "    '''\n",
        "    Função para capturar o título, texto e data de publicação de cada noticia no site resumo do terça livre\n",
        "    '''\n",
        "    import re\n",
        "    import dateparser\n",
        "    lista_noticias = []\n",
        "    try:\n",
        "        #Entra no link de cada noticia\n",
        "        site_noticia = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
        "\n",
        "        #Pega o título\n",
        "        titulo = site_noticia.find('h1', attrs={'class': 'post__title'})\n",
        "\n",
        "        #Pega a data de publicação\n",
        "        data = site_noticia.find('small', attrs={'class': 'post__date'})\n",
        "        try:\n",
        "            date_time_str = dateparser.parse(data.get_text(), languages=[\"pt\"]).strftime('%Y-%m-%d')\n",
        "            date_time = parser.parse(date_time_str).date()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        #Pega o conteúdo textual\n",
        "        container = site_noticia.find('div', attrs={'class': 'post__description'})\n",
        "        textos_noticia = container.findAll('p')\n",
        "        texto_noticia = \" \".join([noti.getText() for noti in textos_noticia])\n",
        "        texto_noticia = re.sub(r'Em tempos de \"censura\", precisamos da ajuda do nosso leitor. [\\s\\S]*/+', ' ', texto_noticia)\n",
        "        texto_noticia = re.sub(r\"ATENÇÃO! Agora você tem a opção de assinatura do JCO com boleto! [\\s\\S]*/+\", ' ', texto_noticia)\n",
        "        texto_noticia = re.sub(r\"Faça a sua assinatura. [\\s\\S]*/+\", ' ', texto_noticia)\n",
        "        texto_noticia = re.sub(r\"Um movimento anônimo, criminoso e fascista está tentando destruir o Jornal da Cidade Online. [\\s\\S]*/+\", ' ', texto_noticia)\n",
        "        texto_noticia = re.sub(r\"Precisamos da ajuda de todos os patriotas. [\\s\\S]*/+\", ' ', texto_noticia)\n",
        "        texto_noticia = re.sub(r\"Fortaleça o jornalismo independente do Jornal da Cidade Online. [\\s\\S]*/+\", ' ', texto_noticia)\n",
        "        texto_noticia = re.sub(r\"Ajude o JCO a continuar sobrevivendo com independência. [\\s\\S]*/+\", ' ', texto_noticia)\n",
        "        texto_noticia = re.sub(r\"Você se incomoda com as publicidades no site\\? [\\s\\S]*/+\", ' ', texto_noticia)\n",
        "\n",
        "        if (titulo and data and texto_noticia and len(texto_noticia)>100):\n",
        "            lista_noticias.append([url, titulo.text, date_time, texto_noticia])\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        #retorna o dataframe com as infos\n",
        "        return pd.DataFrame(lista_noticias, columns=['link','titulo', 'data_pub','noticias'])\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBIxF6EoOH_I"
      },
      "source": [
        "def salva_bases_jornal_cidade_online(ref_in, ref_out, ref):\n",
        "    df = pd.DataFrame()\n",
        "    lista_datas = [i for i in range(ref_in, ref_out)]\n",
        "    for data in lista_datas:\n",
        "        url = return_url_jornal_cidade_online(data)\n",
        "        df = df.append(df_jornal_cidade_online(url))\n",
        "    df = df.reset_index().drop(columns = ['index'])\n",
        "\n",
        "    caminho = \"/Users/rhenanqueiroz/Documents/GitHub/fakenews/jornal_cidade_online_\" + ref + \".pkl\"\n",
        "    df.to_pickle(caminho)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5gHzexVOH_I"
      },
      "source": [
        "# salva_bases_jornal_cidade_online(4700,34000,'geral')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICfOS2DeOH_I"
      },
      "source": [
        "# Brasil de fato"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIIpCX2eOH_J"
      },
      "source": [
        "def return_url_brasil_de_fato(ref):\n",
        "    prefix = 'https://www.brasildefato.com.br/ultimas-noticias?pagina='\n",
        "    sufix = str(ref) + '/'\n",
        "    link_url = prefix + sufix\n",
        "    return link_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXT43zfQOH_J"
      },
      "source": [
        "def df_noticias_brasil_de_fato(url):\n",
        "    '''\n",
        "    Função para capturar o título, texto e data de publicação de cada noticia no site resumo do brasil de fato\n",
        "    '''\n",
        "\n",
        "    # transforma o objeto url na forma do bs4\n",
        "    site = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
        "\n",
        "    #encontra todos os links de noticias do site de resumo diário\n",
        "    links_noticias = site.findAll('a', attrs={'class': 'news-item'})\n",
        "    lista_links = ['https://www.brasildefato.com.br' + link.get('href') for link in links_noticias]\n",
        "    if lista_links:\n",
        "        #Cria lista vazia das noticias do dia com os links\n",
        "        lista_noticias = []\n",
        "\n",
        "        for link in lista_links:\n",
        "\n",
        "            try:\n",
        "\n",
        "                #Entra no link de cada noticia\n",
        "                site_noticia = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "                #Pega o título\n",
        "                titulo = site_noticia.find('h1', attrs={'class': 'title'})\n",
        "\n",
        "\n",
        "                #Pega a data de publicação\n",
        "                data = site_noticia.find('time', attrs={'class': 'date'})\n",
        "                try:\n",
        "                    date_time_str = dateparser.parse(data.get_text(), languages=[\"pt\"]).strftime('%Y-%m-%d')\n",
        "                    date_time = parser.parse(date_time_str).date()\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "                #Pega o conteúdo textual\n",
        "                container = site_noticia.find('div', attrs={'class': 'content'})\n",
        "                textos_noticia = container.findAll('p')\n",
        "                texto_noticia = \" \".join([noti.getText() for noti in textos_noticia])\n",
        "\n",
        "                if (titulo and date_time and texto_noticia and len(texto_noticia)>100):\n",
        "                    lista_noticias.append([link, titulo.text, date_time, texto_noticia])\n",
        "                else:\n",
        "                    pass\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "\n",
        "        #retorna o dataframe com as infos\n",
        "        return pd.DataFrame(lista_noticias, columns=['link','titulo', 'data_pub','noticias'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLqBxQQlOH_J"
      },
      "source": [
        "def salva_bases_brasil_de_fato(ref_in, ref_out, ref):\n",
        "    df = pd.DataFrame()\n",
        "    lista_datas = [i for i in range(ref_in, ref_out)]\n",
        "    df = df.append([df_noticias_brasil_de_fato(return_url_brasil_de_fato(data)) for data in lista_datas])\n",
        "    df = df.reset_index().drop(columns = ['index'])\n",
        "\n",
        "    caminho = \"/Users/rhenanqueiroz/Documents/GitHub/fakenews/brasil_de_fato_\" + ref + \".pkl\"\n",
        "    df.to_pickle(caminho)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiYuIQ7zOH_J"
      },
      "source": [
        "#salva_bases_brasil_de_fato(1,1275,'geral')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__3p3khuOH_K"
      },
      "source": [
        "# El pais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTqE5bgyOH_K"
      },
      "source": [
        "def return_url_elpais(dt):\n",
        "    prefix = 'https://brasil.elpais.com/acervo/'\n",
        "    data_yyyy_mm_dd = str(dt.year) + '-' + dt.strftime('%m') + '-' + dt.strftime('%d') + '/'\n",
        "    link_url = prefix + data_yyyy_mm_dd\n",
        "    return link_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WGRRbZnOH_K"
      },
      "source": [
        "def df_noticias_elpais(url):\n",
        "    '''\n",
        "    Função para capturar o título, texto e data de publicação de cada noticia no site resumo do el pais\n",
        "    '''\n",
        "\n",
        "    # transforma o objeto url na forma do bs4\n",
        "    site = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
        "\n",
        "    #encontra todos os links de noticias do site de resumo diário\n",
        "    links_noticias_cont = site.findAll('h2', class_ = 'c_t')\n",
        "    lista_links = ['https://brasil.elpais.com' + link.find('a').get('href') for link in links_noticias_cont]\n",
        "    if lista_links:\n",
        "        #Cria lista vazia das noticias do dia com os links\n",
        "        lista_noticias = []\n",
        "\n",
        "        for link in lista_links:\n",
        "\n",
        "            try:\n",
        "\n",
        "                #Entra no link de cada noticia\n",
        "                site_noticia = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "                #Pega o título\n",
        "                titulo = site_noticia.find('h1', attrs={'class': 'a_t'})\n",
        "\n",
        "\n",
        "                #Pega a data de publicação\n",
        "                data = site_noticia.find('a', attrs={'id': 'article_date_p'})\n",
        "                try:\n",
        "                    date_time_str = dateparser.parse(data.get_text(), languages=[\"pt\"]).strftime('%Y-%m-%d')\n",
        "                    date_time = parser.parse(date_time_str).date()\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "                #Pega o conteúdo textual\n",
        "                container = site_noticia.find('div', attrs={'class': 'a_c clearfix'})\n",
        "                textos_noticia = container.findAll('p')\n",
        "                texto_noticia = \" \".join([noti.getText() for noti in textos_noticia])\n",
        "\n",
        "                if (titulo and date_time and texto_noticia and len(texto_noticia)>100):\n",
        "                    lista_noticias.append([link, titulo.text, date_time, texto_noticia])\n",
        "                else:\n",
        "                    pass\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "\n",
        "        #retorna o dataframe com as infos\n",
        "        return pd.DataFrame(lista_noticias, columns=['link','titulo', 'data_pub','noticias'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX-gki4WOH_K"
      },
      "source": [
        "def salva_bases_elpais(ref_in, ref_out, ref):\n",
        "    df = pd.DataFrame()\n",
        "    lista_datas = pd.date_range(start=ref_in, end=ref_out)\n",
        "    for data in lista_datas:\n",
        "        url = return_url_elpais(data)\n",
        "        df = df.append(df_noticias_elpais(url))\n",
        "    df = df.reset_index().drop(columns = ['index'])\n",
        "    caminho = \"/Users/rhenanqueiroz/Documents/GitHub/fakenews/elpais_\" + ref + \".pkl\"\n",
        "    df.to_pickle(caminho)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mQ7CcqSOH_L"
      },
      "source": [
        "#salva_bases_elpais('2017-01-01','2021-10-30','geral')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYWBsfU2OH_L"
      },
      "source": [
        "# Conexão política"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzRrnqO6OH_L"
      },
      "source": [
        "def return_url_conexao_politica(ref):\n",
        "    prefix = 'https://www.conexaopolitica.com.br/todos-conteudos/page/'\n",
        "    sufix = str(ref) + '/'\n",
        "    link_url = prefix + sufix\n",
        "    return link_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVz3cN-kOH_L"
      },
      "source": [
        "def df_noticias_conexao_politica(url):\n",
        "    '''\n",
        "    Função para capturar o título, texto e data de publicação de cada noticia no site resumo do conexao politica\n",
        "    '''\n",
        "\n",
        "    # transforma o objeto url na forma do bs4\n",
        "    site = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
        "\n",
        "    #encontra todos os links de noticias do site de resumo diário\n",
        "    links_noticias_cont = site.findAll('div', class_ = 'zox-art-title')\n",
        "    lista_links = [link.find('a').get('href') for link in links_noticias_cont]\n",
        "    if lista_links:\n",
        "        #Cria lista vazia das noticias do dia com os links\n",
        "        lista_noticias = []\n",
        "\n",
        "        for link in lista_links:\n",
        "\n",
        "            try:\n",
        "\n",
        "                #Entra no link de cada noticia\n",
        "                site_noticia = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "                #Pega o título\n",
        "                titulo = site_noticia.find('h1')\n",
        "\n",
        "\n",
        "                #Pega a data de publicação\n",
        "                data = site_noticia.find('time').get('datetime')\n",
        "                date_time = parser.parse(data).date()\n",
        "\n",
        "                #Pega o conteúdo textual\n",
        "                container = site_noticia.find('div', attrs={'class': 'zox-post-body left zoxrel zox100'})\n",
        "                textos_noticia = container.findAll('p')\n",
        "                texto_noticia = \" \".join([noti.getText() for noti in textos_noticia])\n",
        "\n",
        "                if (titulo and date_time and texto_noticia and len(texto_noticia)>100):\n",
        "                    lista_noticias.append([link, titulo.text, date_time, texto_noticia])\n",
        "                else:\n",
        "                    pass\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "\n",
        "        #retorna o dataframe com as infos\n",
        "        return pd.DataFrame(lista_noticias, columns=['link','titulo', 'data_pub','noticias'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9iRpIQ5OH_L"
      },
      "source": [
        "def salva_bases_conexao_politica(ref_in, ref_out, ref):\n",
        "    df = pd.DataFrame()\n",
        "    lista_datas = [i for i in range(ref_in, ref_out)]\n",
        "    df = df.append([df_noticias_conexao_politica(return_url_conexao_politica(data)) for data in lista_datas])\n",
        "    df = df.reset_index().drop(columns = ['index'])\n",
        "\n",
        "    caminho = \"/Users/rhenanqueiroz/Documents/GitHub/fakenews/conexao_politica_\" + ref + \".pkl\"\n",
        "    df.to_pickle(caminho)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTWRWawTOH_M"
      },
      "source": [
        "#salva_bases_conexao_politica(1, 1592, 'geral')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jHzGupPOH_M"
      },
      "source": [
        "# Agregando todos os textos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as1xg16WOH_M"
      },
      "source": [
        "df_g1 = pd.read_pickle('g1_geral.pkl')\n",
        "df_elpais = pd.read_pickle('elpais_geral.pkl')\n",
        "df_jco = pd.read_pickle('jornal_cidade_online_geral.pkl')\n",
        "df_si = pd.read_pickle('senso_incomum_geral.pkl')\n",
        "df_bdf = pd.read_pickle('brasil_de_fato_geral.pkl')\n",
        "df_cnxpol = pd.read_pickle('conexao_politica_geral.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8nWlEJcOH_M",
        "outputId": "6eb3ec54-0e52-4156-82e9-3780cb5f9474"
      },
      "source": [
        "df_geral = df_g1.append(df_elpais).append(df_jco).append(df_si).append(df_bdf).append(df_cnxpol)\n",
        "len(df_geral)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83256"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-YdH8NKOH_M"
      },
      "source": [
        "# Limpeza dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQXpj1PIOH_N"
      },
      "source": [
        "import re\n",
        "def limpa_texto(texto):\n",
        "    # remove \\n e \\r\n",
        "    c = re.sub(r'\\n', ' ', texto)\n",
        "    c = re.sub(r'\\r', ' ', c)\n",
        "\n",
        "    # remove emoction\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    c = emoji_pattern.sub(r'', c)\n",
        "\n",
        "    # remove os @ listados\n",
        "    c = re.sub(r'@[\\w./-]+', '', c)\n",
        "\n",
        "    # remove os sites\n",
        "    c = re.sub(r'http[\\w./:-]+', '', c)\n",
        "\n",
        "    # remove tag html\n",
        "    c = re.sub(r'<.*?>','', c)\n",
        "\n",
        "    # remove caracteres não alfabéticos\n",
        "    c = c.replace(':', ' ')\n",
        "    c = c.replace(';', ' ')\n",
        "    c = c.replace('.', ' ')\n",
        "    c = c.replace('/', ' ')\n",
        "    c = re.sub(r'R\\$', '', c)\n",
        "    c = re.sub(r'\\W', ' ', c)\n",
        "    c = re.sub('[‘’“”…]', '', c)\n",
        "    c = re.sub('\\w*\\d\\w*', '', c)\n",
        "\n",
        "    # remove espaços adicionais\n",
        "    c = re.sub(r'\\s+', ' ', c)\n",
        "\n",
        "    # remove espacos adicionais no inicio das frases\n",
        "    c = re.sub(r'^\\s+', '', c)\n",
        "\n",
        "    # remove espacos adicionais no final das frases\n",
        "    c = re.sub(r'\\s+$', '', c)\n",
        "\n",
        "    #remove palavras que tenham mais de 3 letras repetidas seguidas e qq outro\n",
        "    c = re.sub(r'\\w+?(\\w)\\1{2,}(\\w)+\\b', '', c)\n",
        "\n",
        "    #remove risadas\n",
        "    c = re.sub(r'(h?a*ha+h[ha]*.)', '', c)\n",
        "\n",
        "    #retira acentos\n",
        "    c = c.replace(\"á\",\"a\")\n",
        "    c = c.replace(\"ã\",\"a\")\n",
        "    c = c.replace(\"õ\",\"o\")\n",
        "    c = c.replace(\"é\",\"e\")\n",
        "    c = c.replace(\"í\",\"i\")\n",
        "    c = c.replace(\"ó\",\"o\")\n",
        "    c = c.replace(\"ô\",\"o\")\n",
        "    c = c.replace(\"ú\",\"u\")\n",
        "    c = c.replace(\"ç\",\"c\")\n",
        "\n",
        "    return c\n",
        "\n",
        "def stemmatiza(texto):\n",
        "    doc = nltk.word_tokenize(texto)\n",
        "    return ' '.join(stemmer.stem(token.lower()) for token in doc)\n",
        "\n",
        "def remove_stop(texto):\n",
        "    doc = nltk.word_tokenize(texto)\n",
        "    return \" \".join(token for token in doc if token not in stopwords)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y18020e2OH_N"
      },
      "source": [
        "df_geral['noticias_limpas'] = df_geral['noticias'].apply(lambda x: limpa_texto(x))\\\n",
        "                                                  .apply(lambda x: remove_stop(x))\n",
        "\n",
        "df_geral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_geral.to_pickle('todas_noticias.pkl')"
      ],
      "metadata": {
        "id": "hqmKPBx2ii13"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}